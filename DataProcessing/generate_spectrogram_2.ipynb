{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "import matplotlib.style as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "import multiprocessing as mp\n",
    "\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_df = pd.read_csv('multimodal-speech-emotion-recognition-master/Preprocessing/df_iemocap/df_iemocap.csv')\n",
    "iemocap_dir = 'IEMOCAP_full_release_withoutVideos/Iemocap_sentences/'\n",
    "save_dir = 'Preprocessing/AudioVectors/'\n",
    "audio_vectors_path= save_dir + 'audio_vectors_'\n",
    "\n",
    "print(labels_df.emotion.value_counts())\n",
    "emotion_dict = {'ang': 0,\n",
    "                'hap': 1,\n",
    "                'exc': 2,\n",
    "                'sad': 3,\n",
    "                'fru': 4,\n",
    "                'fea': 5,\n",
    "                'sur': 6,\n",
    "                'neu': 7,\n",
    "                'xxx': 8,\n",
    "                'oth': 8,\n",
    "                'dis': 8}\n",
    "emotion_full_dict = {'neu': 'neutral', 'ang': 'anger', 'hap': 'happiness', 'exc': 'excited', 'sad': 'sadness',\n",
    "                     'fru':'frustrated', 'fea': 'fear', 'sur': 'surprised', 'xxx': 'others', 'oth': 'others', 'dis': 'others'}\n",
    "\n",
    "labels_df_subset = labels_df[labels_df[\"emotion\"].isin([\"neu\", 'ang', 'hap', 'sad'])]\n",
    "\n",
    "labels_df_subset = labels_df_subset[[\"wav_file\", \"emotion\"]]\n",
    "\n",
    "labels_df_subset = labels_df_subset.rename(columns={\"wav_file\": \"filename\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle_to_df = pd.read_csv('Preprocessing/pickle_to_audiodf/pickle_to_audiodf.csv')\n",
    "\n",
    "del pickle_to_df['Unnamed: 0']\n",
    "\n",
    "pickle_to_subset = labels_df_subset.merge(pickle_to_df, on=\"filename\",right_index=True)\n",
    "\n",
    "print(pickle_to_subset.shape)\n",
    "print(pickle_to_df.shape)\n",
    "print(labels_df_subset.shape)\n",
    "\n",
    "pickle_to_subset.to_csv('Preprocessing/pickle_to_subset/pickle_to_subset.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
